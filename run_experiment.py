import argparse
import sys
from pathlib import Path

from data_collector import ResponseCollector
from prompts import PROMPTS
from config import JSON_DIR, OUTPUT_DIR, get_models, MODEL_SET


def print_banner():
    """ĞŸĞµÑ‡Ğ°Ñ‚ÑŒ Ğ±Ğ°Ğ½Ğ½ĞµÑ€Ğ°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘         TABLE HEADER DETECTION EXPERIMENT                    â•‘
â•‘         Benchmarking LLMs on Structured Data                 â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


def main():
    print_banner()
    
    parser = argparse.ArgumentParser(
        description='Table Header Detection Experiment',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--model-set',
        choices=['small', 'medium', 'all'],
        default=MODEL_SET,
        help='ĞĞ°Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· config.py)'
    )
    
    parser.add_argument(
        '--prompts',
        nargs='+',
        type=int,
        metavar='INDEX',
        help='Ğ˜Ğ½Ğ´ĞµĞºÑÑ‹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (0-12). Ğ•ÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ²ÑĞµ'
    )
    
    parser.add_argument(
        '--list-prompts',
        action='store_true',
        help='ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ² Ğ¸ Ğ²Ñ‹Ğ¹Ñ‚Ğ¸'
    )
    
    parser.add_argument(
        '--output',
        default=OUTPUT_DIR,
        help=f'Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ: {OUTPUT_DIR})'
    )
    
    parser.add_argument(
        '--test',
        action='store_true',
        help='Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº Ñ 2 Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ¸ 3 Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°Ğ¼Ğ¸'
    )
    
    parser.add_argument(
        '--yes', '-y',
        action='store_true',
        help='ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ'
    )
    
    args = parser.parse_args()
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²
    if args.list_prompts:
        print("\nğŸ“ Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞĞ«Ğ• ĞŸĞ ĞĞœĞŸĞ¢Ğ«:")
        print("="*70)
        for i, p in enumerate(PROMPTS):
            print(f"{i:2d}. {p['name']}")
        print("="*70)
        print(f"\nĞ’ÑĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²: {len(PROMPTS)}")
        print("\nĞ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: python run_experiment.py --prompts 0 1 3")
        return
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    if args.test:
        models = get_models()[:2]  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ 2 Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        selected_prompts = PROMPTS[:3]  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ 3 Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°
        print("\nğŸ§ª Ğ¢Ğ•Ğ¡Ğ¢ĞĞ’Ğ«Ğ™ Ğ Ğ•Ğ–Ğ˜Ğœ")
    else:
        # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ MODEL_SET Ğ¸Ğ· Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        import config
        config.MODEL_SET = args.model_set
        models = get_models()
        
        # Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²
        if args.prompts:
            selected_prompts = []
            for idx in args.prompts:
                if 0 <= idx < len(PROMPTS):
                    selected_prompts.append(PROMPTS[idx])
                else:
                    print(f"âš ï¸  ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ: Ğ˜Ğ½Ğ´ĞµĞºÑ {idx} Ğ²Ğ½Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° (0-{len(PROMPTS)-1})")
            
            if not selected_prompts:
                print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: ĞĞµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ¾ Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°")
                return
        else:
            selected_prompts = PROMPTS
    
    # Ğ’Ñ‹Ğ²Ğ¾Ğ´ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
    print(f"\n{'='*70}")
    print("ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢Ğ")
    print(f"{'='*70}")
    print(f"\nğŸ“Š ĞœĞ¾Ğ´ĞµĞ»Ğ¸ ({len(models)}):")
    for i, model in enumerate(models, 1):
        print(f"  {i:2d}. {model}")
    
    print(f"\nğŸ“ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ ({len(selected_prompts)}):")
    for i, prompt in enumerate(selected_prompts, 1):
        print(f"  {i:2d}. {prompt['name']}")
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†
    json_path = Path(JSON_DIR)
    if not json_path.exists():
        print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°Ğ¼Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {JSON_DIR}")
        print(f"ğŸ’¡ Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ğ¿ÑƒÑ‚ÑŒ ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ Ğ² config.py Ğ¸Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ JSON_DIR")
        return
    
    if not json_path.is_dir():
        print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: {JSON_DIR} Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸ĞµĞ¹")
        return
    
    table_files = list(json_path.glob("*.json"))
    if not table_files:
        print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ’ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ {JSON_DIR} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ JSON Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
        print(f"ğŸ’¡ Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ JSON Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸")
        return
    
    print(f"\nğŸ“„ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†: {len(table_files)}")
    
    # ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    total_requests = len(models) * len(selected_prompts) * len(table_files)
    estimated_time_min = total_requests * 2 / 60  # ~2 ÑĞµĞº Ğ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
    
    print(f"\n{'='*70}")
    print(f"ğŸ¯ Ğ‘ÑƒĞ´ĞµÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {total_requests}")
    print(f"â±ï¸  ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ: {estimated_time_min:.1f} Ğ¼Ğ¸Ğ½ÑƒÑ‚")
    print(f"ğŸ’¾ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ±ÑƒĞ´ÑƒÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {args.output}")
    print(f"{'='*70}")
    
    # ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ
    if not args.yes and not args.test:
        response = input("\nâ“ ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ? (y/n): ")
        if response.lower() != 'y':
            print("âŒ ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")
            return
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞ±Ğ¾Ñ€Ğ°
    print(f"\n{'='*70}")
    print("ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢Ğ")
    print(f"{'='*70}\n")
    
    try:
        collector = ResponseCollector(
            json_dir=JSON_DIR,
            output_dir=args.output
        )
        
        collector.collect_responses(models, selected_prompts)
        
        print(f"\n{'='*70}")
        print("âœ… Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•Ğ")
        print(f"{'='*70}")
        print(f"\nğŸ“ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {args.output}")
        print("\nğŸ’¡ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³: Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ analyzer.py Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²")
        print(f"   python analyzer.py {args.output}/responses_*.json")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")
        print("ğŸ’¾ ĞŸÑ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² checkpoint Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…")
    except Exception as e:
        print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()